{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d19fbdf8",
   "metadata": {
    "id": "d19fbdf8"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.compat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11472\\1701135222.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.compat'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow.compat.v2 as tf\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5VkMcV3yJab8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5VkMcV3yJab8",
    "outputId": "cc3e4672-e11a-46fb-82d6-233c6219139b"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5745a48f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5745a48f",
    "outputId": "67bd5427-f69a-41e4-f64e-763af38ed6d8"
   },
   "outputs": [],
   "source": [
    "print(os.listdir(\"/content/drive/Othercomputers/My Laptop/COEN 281/COEN 281/Project/Pneumonia-Detection-on-Chest-Xrays/chest_xray\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75922616",
   "metadata": {
    "id": "75922616"
   },
   "outputs": [],
   "source": [
    "data_dir = Path(\"/content/drive/Othercomputers/My Laptop/COEN 281/COEN 281/Project/Pneumonia-Detection-on-Chest-Xrays/chest_xray/chest_xray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ba3f2b",
   "metadata": {
    "id": "a1ba3f2b"
   },
   "outputs": [],
   "source": [
    "train_dir = data_dir / 'train'\n",
    "val_dir = data_dir / 'val'\n",
    "test_dir = data_dir / 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f7c925",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "f9f7c925",
    "outputId": "13fc24dc-bd40-4ace-d53c-a559b8e80be5"
   },
   "outputs": [],
   "source": [
    "train_normal_dir = train_dir / 'NORMAL'\n",
    "train_pneumonia_dir = train_dir / 'PNEUMONIA'\n",
    "\n",
    "normal_cases = train_normal_dir.glob('*jpeg')\n",
    "pneumonia_cases = train_pneumonia_dir.glob('*jpeg')\n",
    "\n",
    "train_data = []\n",
    "for img in normal_cases:\n",
    "    train_data.append((img, 0))\n",
    "for img in pneumonia_cases:\n",
    "    train_data.append((img, 1))\n",
    "\n",
    "train_df = pd.DataFrame(train_data, columns = ['Image Path', 'Label'], index = None)\n",
    "train_df = train_df.sample(frac = 1.).reset_index(drop = True)\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd3d9f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "2fd3d9f9",
    "outputId": "078aeaf9-35ea-430f-b37f-0e193f32905f"
   },
   "outputs": [],
   "source": [
    "case_count = train_df['Label'].value_counts()\n",
    "print(case_count)\n",
    "plt.figure(figsize = (6, 4))\n",
    "sns.barplot(x = case_count.index, y = case_count.values)\n",
    "plt.title('Number of Cases')\n",
    "plt.xlabel('Case type')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(range(len(case_count.index)), ['Normal(0)', 'Pneumonia(1)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca1967",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "76ca1967",
    "outputId": "51dd3e8f-4ea3-4ea3-b198-19f5b3bc3641"
   },
   "outputs": [],
   "source": [
    "samples_pneumonia = (train_df[train_df['Label'] == 1]['Image Path'].iloc[:5]).tolist()\n",
    "samples_normal = (train_df[train_df['Label'] == 0]['Image Path'].iloc[:5]).tolist()\n",
    "\n",
    "total_samples = samples_pneumonia + samples_normal\n",
    "del samples_pneumonia, samples_normal\n",
    "\n",
    "f, ax = plt.subplots(2, 5, figsize=(30,10))\n",
    "for i in range(0, 10):\n",
    "    img = imread(total_samples[i])\n",
    "    ax[i // 5, i % 5].imshow(img, cmap='gray')\n",
    "    if i < 5:\n",
    "        ax[i // 5, i % 5].set_title(\"Pneumonia\", size=20)\n",
    "    else:\n",
    "        ax[i // 5, i % 5].set_title(\"Normal\", size=20)\n",
    "    ax[i // 5, i % 5].axis('off')\n",
    "    ax[i // 5, i % 5].set_aspect('auto')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NGUllnJODs4F",
   "metadata": {
    "id": "NGUllnJODs4F"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255.\n",
    "train_datagen = ImageDataGenerator( rescale = 1.0/255.,\n",
    "                                  rotation_range=20 ,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  brightness_range=[0.6,0.9],\n",
    "                                  fill_mode='nearest')\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbvsnvd8ETC2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fbvsnvd8ETC2",
    "outputId": "0e88c173-3842-4356-ac6f-7925c8a64102"
   },
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "# --------------------\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(300, 300))     \n",
    "# --------------------\n",
    "# Flow validation images using test_datagen generator\n",
    "# --------------------\n",
    "validation_generator =  test_datagen.flow_from_directory(val_dir,\n",
    "                                                         shuffle=False,\n",
    "                                                         class_mode  = 'binary',\n",
    "                                                         target_size = (300, 300))\n",
    "\n",
    "# --------------------\n",
    "# Flow validation images using test_datagen generator\n",
    "# --------------------\n",
    "test_generator =  test_datagen.flow_from_directory(test_dir,\n",
    "                                                         shuffle=False,\n",
    "                                                         class_mode  = 'binary',\n",
    "                                                         target_size = (300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xc61WcGNEXeh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xc61WcGNEXeh",
    "outputId": "d4cd0b99-2034-4248-fb83-e7a5434d208f"
   },
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_UYweefhEYwI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 968
    },
    "id": "_UYweefhEYwI",
    "outputId": "85aaab37-0bb9-4f15-c15a-c84f8950338f"
   },
   "outputs": [],
   "source": [
    "# viualize some images after the augmentation\n",
    "x_batch, y_batch = next(train_generator)\n",
    "W = 5\n",
    "H = 5\n",
    "fig, axes = plt.subplots(W, H, figsize = (17,17))\n",
    "\n",
    "axes = axes.ravel() # flaten the matrix into array\n",
    "for i in np.arange(0, W * H): \n",
    "\n",
    "    # Select a random image\n",
    "    image = x_batch[i]\n",
    "    # read and display an image with the selected index    \n",
    "    axes[i].imshow( image )\n",
    "    axes[i].set_title(y_batch[i], fontsize = 8) # the label\n",
    "    axes[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7gTwILTWI0D9",
   "metadata": {
    "id": "7gTwILTWI0D9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KTejLoK4Ek7I",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KTejLoK4Ek7I",
    "outputId": "0dbda575-2253-41da-9b97-d542d84c627c"
   },
   "outputs": [],
   "source": [
    "vgg_model = tf.keras.applications.VGG19(\n",
    "    weights='imagenet',\n",
    "    include_top = False,\n",
    "#     input_shape = (224,224,3)\n",
    ")\n",
    "\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "x = vgg_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "# output layer\n",
    "predictions = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=vgg_model.input, outputs=predictions)\n",
    "\n",
    "# to avoid overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=10)\n",
    "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',patience=8)\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ObPqZP9ZIM4J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ObPqZP9ZIM4J",
    "outputId": "9d80fb29-e4d2-4c1d-d1cd-8ea8ac184156"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6iMrKp6yJWXN",
   "metadata": {
    "id": "6iMrKp6yJWXN"
   },
   "outputs": [],
   "source": [
    "best_model = ModelCheckpoint('.mdl_wts.hdf5', save_best_only = True, monitor = 'val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CLhrIlQsJaX0",
   "metadata": {
    "id": "CLhrIlQsJaX0"
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('model-{epoch:03d}-{accuracy:03f}-{val_accuracy:03f}.h5', \n",
    "                             verbose=1, \n",
    "                             monitor='val_accuracy',\n",
    "                             save_best_only=True, \n",
    "                             mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cjgGvPcpJKdb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cjgGvPcpJKdb",
    "outputId": "e46b37a1-4ecf-45c8-d4c3-b07c3b1d36f0"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator ,epochs=30, \n",
    "                    validation_data=validation_generator,\n",
    "                     steps_per_epoch=100,\n",
    "                    callbacks=[checkpoint,early_stopping,lr],\n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mfurJc0gIWC1",
   "metadata": {
    "id": "mfurJc0gIWC1"
   },
   "outputs": [],
   "source": [
    "def evaluation(history):\n",
    "    # evaluation\n",
    "    #-----------------------------------------------------------\n",
    "    # Retrieve a list of list results on training and test data\n",
    "    # sets for each training epoch\n",
    "    #-----------------------------------------------------------\n",
    "    acc      = history.history['accuracy']\n",
    "    val_acc  = history.history['val_accuracy']\n",
    "    loss     = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs   = range(len(acc)) # Get number of epochs\n",
    "\n",
    "    #------------------------------------------------\n",
    "    # Plot training and validation accuracy per epoch\n",
    "    #------------------------------------------------\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot  ( epochs,     acc )\n",
    "    plt.plot  ( epochs, val_acc )\n",
    "    plt.title ('Training and validation accuracy')\n",
    "    #------------------------------------------------\n",
    "    # Plot training and validation loss per epoch\n",
    "    #------------------------------------------------\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot  ( epochs,     loss )\n",
    "    plt.plot  ( epochs, val_loss )\n",
    "    plt.title ('Training and validation loss'   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jzWV71q3IYUF",
   "metadata": {
    "id": "jzWV71q3IYUF"
   },
   "outputs": [],
   "source": [
    "evaluation(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "S5qPU031IbPA",
   "metadata": {
    "id": "S5qPU031IbPA"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "#Confution Matrix and Classification Report\n",
    "Y_pred = model.predict(validation_generator)\n",
    "model.evaluate(validation_generator)\n",
    "y_pred= np.where(Y_pred>0.5, 1, 0)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = os.listdir(train_dir)\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Predicted classes', size=14)\n",
    "sns.heatmap(confusion_matrix(validation_generator.classes, y_pred), annot=True, fmt = '.0f',linewidths=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-grb1YVyIdx5",
   "metadata": {
    "id": "-grb1YVyIdx5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "#Confution Matrix and Classification Report\n",
    "Y_pred = model.predict(test_generator)\n",
    "model.evaluate(test_generator)\n",
    "y_pred= np.where(Y_pred>0.5, 1, 0)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = os.listdir(train_dir)\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=target_names))\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title('Predicted classes', size=14)\n",
    "sns.heatmap(confusion_matrix(test_generator.classes, y_pred), annot=True, fmt = '.0f',linewidths=.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
